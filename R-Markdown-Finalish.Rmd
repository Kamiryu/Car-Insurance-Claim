---
title: "Car Insurance Claims"
author: "Fabien Roduit"
date: "2022-12-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Libraries
```{r}
library(naniar)       # Missing values
library(ggplot2)      # Graphics
library(dplyr)
library(tidyr)
library(randomForest) # Random forest
library(corrplot)     # Plot correlations
library(knitr)         #Table presentation
library(GGally)       # Correlation and scatter plots
library(class)       # knn
library(rpart)       # trees
library(caret)       # preprocess data
library(rpart.plot)     # plot trees
library(forecast)       # accuracy
source("PlotResidLogist.R") # Deviance Residuals
source("HosLemTest.R") # Hosmerâ€“Lemeshow goodness of fit
library(doParallel)#Accelerating computations by setting CPU to work in parallel
cores = detectCores()
cl <- makeCluster(cores-1)
registerDoParallel(cl)
```

```{r,warning=FALSE}
cars <- read.csv("train.csv", sep=",", header = TRUE)

str(cars)

cars <- cars[,c(-1)] # Drop ID

sapply(cars,function(x) length(unique(x))) # Check unique values

gg_miss_var(cars, show_pct = TRUE) # See if any missing value
```

```{r}
#Histograms
cars %>% select(1:3, 5:6,13,20:21,23,25:29,42:43) %>% gather() %>% 
 ggplot(aes(value)) + 
 facet_wrap(~ key, scales = "free") + 
 geom_histogram(color = "black", fill = "#6baed6") + 
 theme_minimal()


# Barcharts
cars %>% select(4,7:12,14:19,22,24,30:41) %>% gather() %>%
 ggplot(aes(x = value)) +
 facet_wrap(~ key, scales = "free") +
 geom_bar(color = "black", fill = "#6baed6") +
 theme_minimal()
```

```{r}
cars_numeric <- cars[,c(1:3, 5:6,13,20:21,23,25:29,42)] # Only numerical values

# Correlations
cor2 <- data.frame(round(cor(cars_numeric),3))
cor2

# Plot correlations
corrplot(as.matrix(cor2), order = 'AOE', type = 'lower', tl.pos = "lt",tl.cex = 0.5,)
corrplot(as.matrix(cor2), add = TRUE, type = 'upper', method = 'ellipse', order = 'AOE',
        diag = FALSE, tl.pos = 'n', cl.pos = 'n',tl.cex = 0.5)

# Dropping variables based on correlation
cars_reduced <- cars[,-c(20,13,23,25,29)]
```

```{r}
# Commented to avoid computing for the moment
# rf_fit <- randomForest(as.factor(cars$is_claim) ~ ., # Fit a random # forest with reduced set
#                        data = cars_reduced,
#                        ntree = 500,
#                        mtry = 4,
#                        importance = TRUE)
# 
# 
# rf_fit$importance[,3]
# 
# sort(round(rf_fit$importance[,4],3), decreasing = TRUE)
# 
# varImpPlot(rf_fit, type = 1)

cars_reduced_rf <- cars_reduced[,c("policy_tenure","age_of_car","age_of_policyholder",
                        "population_density","area_cluster","height",
                        "width","segment","model","length","engine_type",
                        "max_torque","max_power","ncap_rating","cylinder")]
```

Variable importance: <https://plos.figshare.com/articles/figure/Variable_importance_plot_mean_decrease_accuracy_and_mean_decrease_Gini_/12060105/1#>:\~:text=The%20mean%20decrease%20in%20Gini,the%20variable%20in%20the%20model.


```{r}
# Correlations
cor3 <- data.frame(round(cor(cars_reduced_rf[,c(1:4,6,7,10,14,15)]),3))
cor3

corrplot(as.matrix(cor3), order = 'AOE', type = 'lower', tl.pos = "lt",tl.cex = 0.5,)
corrplot(as.matrix(cor3), add = TRUE, type = 'upper', method = 'ellipse', order = 'AOE',
        diag = FALSE, tl.pos = 'n', cl.pos = 'n',tl.cex = 0.5)



# Filtering variables based on domain knowledge and correlations

cars_reduced <- cars_reduced_rf[,-c( 7,8,11,12,13,14,15)]
cars_final <- cbind(cars_reduced, cars$is_claim)
colnames(cars_final)[9] <- "is_claim"
```

```{r}
# We drop height and weight since model defines these features.

logistic_regression_final_variables <- glm(is_claim~., family=binomial(link='logit')
, data= cars_final[,-c(5,7)])

summary(logistic_regression_final_variables)

```


We can see that  the coefficient NA for cluster9 is symptomatic of a multicolinearity issue. Therefore, we remove area cluster and keep population instead.
```{r}
logistic_regression_final_variables <- glm(is_claim~., family=binomial(link='logit')
, data= cars_final[,-c(5,7,4)])

summary(logistic_regression_final_variables)
```

```{r}
cars_final <- cars_final[,-c(5,6,8)]
kable(head(cars_final), format="markdown")
```

Based on our previous analysis, our finals explanatory variables would be: policy_tenure, age_of_car, age_of_policyholder, model and population_density.


# EDA

```{r}
#Histograms
cars_final %>% select(1:4,6) %>% gather() %>% 
 ggplot(aes(value)) + 
 facet_wrap(~ key, scales = "free") + 
 geom_histogram(color = "black", fill = "#69b3a2") + 
  theme(plot.title=element_text(hjust=0.5),
        panel.background = element_rect(fill = "white"),
        panel.grid.major.y = element_line(color = "grey98")) 
```

```{r}
# Barcharts
cars_final %>% select(5)  %>% gather() %>%
 ggplot(aes(x = value)) +
 facet_wrap(~ key, scales = "free") +
 geom_bar(color = "black", fill = "#69b3a2") +
  theme(plot.title=element_text(hjust=0.5),
        panel.background = element_rect(fill = "white"),
        panel.grid.major.y = element_line(color = "grey98"))


# boxplot
cars_final %>% select(1:4)  %>% gather() %>%
 ggplot(aes(x = value,y="")) +
  
  facet_wrap(~ key, scales = "free")+
                   # add horizontal line to "whiskers" of boxplot
  geom_boxplot(fill = "#6baed6", width = 0.5) + 
  stat_boxplot(geom = "errorbar", width = 0.2) +# plot boxplot
  stat_summary(fun.y=mean, colour="darkred", geom="point", shape=18, size=3,show_guide = FALSE)+
  theme_classic() +
  theme(plot.title=element_text(hjust=0.5),
        panel.background = element_rect(fill = "white"),
        panel.grid.major.y = element_line(color = "grey98")) 


```

We can see that the distribution of the data is not symmetrical. However, since the data is already normalized, we are not able to do a log transform on the data except for population density.

```{r}
cars_final$population_density <- log(cars_final$population_density)

normalized.pop <- (cars_final$population_density - min (cars_final$population_density)) / (max(cars_final$population_density)-min(cars_final$population_density))

cars_final$population_density <- as.vector(normalized.pop)
```

```{r}
# boxplot
cars_final %>% select(1:4)  %>% gather() %>%
 ggplot(aes(x = value,y="")) +
  
  facet_wrap(~ key, scales = "free")+
                   # add horizontal line to "whiskers" of boxplot
  geom_boxplot(fill = "#6baed6", width = 0.5) + 
  stat_boxplot(geom = "errorbar", width = 0.2) +# plot boxplot
  stat_summary(fun.y=mean, colour="darkred", geom="point", shape=18, size=3,show_guide = FALSE)+
  theme_classic() +
  theme(plot.title=element_text(hjust=0.5),
        panel.background = element_rect(fill = "white"),
        panel.grid.major.y = element_line(color = "grey98")) 
```

With the log transformation on population_density, the distribution has become a little bit more centered and symmetrical.

```{r}
kable(summary(cars_final), format="markdown")
```

```{r}
# Commented for time computing
# ggpairs(cars_final[,c(1:4,6)])+
#   theme_bw()
```

We can see from the plots above that our remaining variables are not highly correlated between them.

```{r}
#boxplot for the distribution of 0 1 
df = cars_final[, -5] 
df$is_claim <- as.factor(df$is_claim)
library(reshape2)
df.melt = melt(df)
# HEAD

df.boxplot = ggplot(df.melt, aes(y=value,is_claim)) + 
  geom_boxplot() + 
  facet_wrap(~variable, scales = "free", ncol=3) + theme_classic() + xlab("Variables")

df.boxplot

```

```{r}
barplot(prop.table(table(cars$is_claim)),
        col = rainbow(2),
        ylim = c(0, 1),
        main = "Class Distribution")
```


```{r}
df.boxplot = ggplot(df.melt, aes(y=value,is_claim)) + 
  geom_boxplot() + 
  facet_wrap(~variable, scales = "free", ncol=3) + theme_classic() + xlab("Variables")

df.boxplot

```

```{r}
barplot(prop.table(table(cars$is_claim)),
        col = rainbow(2),
        ylim = c(0, 1),
        main = "Class Distribution") # outcome variable distribution 
prop.table(table(cars$is_claim))
```
When the proportions of the different classes in a classification problem are imbalanced (in our case 1 present about 6% from is_claim), it means that one class (the majority class) is much more frequent than the other class(es) (the minority class(es)). This can cause the model to have a high performance (e.g. high F1-score) on the majority class and low performance on the minority class.

To address this issue, we can re-sample the data to create a more balanced distribution of the classes. This can be done using techniques such as undersampling (removing examples from the majority class) or oversampling . These techniques can help the model to better learn from the minority class and improve its performance on it.

```{r}
proportions(table(cars_final$is_claim))

set.seed(1)
index <- sample(nrow(cars_final),nrow(cars_final)*0.60)
cars_train = cars_final[index,]
cars_validation = cars_final[-index,]

proportions(table(cars_train$is_claim))
proportions(table(cars_validation$is_claim))

```



```{r}
# Add dummy variables 
cars_final$model <- as.factor(cars_final$model)                       # change variable format to factor 

dummies <- dummyVars(~ ., data = cars_final)                             # create object for dummy variables
cars_final_dummy <- as.data.frame(predict(dummies, newdata = cars_final))      # apply dummies to data

cars_final$is_claim <- as.factor(cars_final$is_claim)                # change variable format to factor
cars_final_dummy$is_claim <- as.factor(cars_final_dummy$is_claim) 

head(cars_final_dummy)                                                  # resulting in 11
str(cars_final_dummy)

train_dummy <- cars_final_dummy[index,] # training set with dummies  
valid_dummy <- cars_final_dummy[-index,] #validation set with dummies
train_new <- downSample(train_dummy[,-16],train_dummy$is_claim,yname = "is_claim") # undersampling for having same probation 
str(train_new)
proportions(table(train_new$is_claim))

summary(train_new$is_claim)

```




## KNN
```{r}
# Find optimal k

# Data frame for k from 1 to 50 and respective accuracy
accuracy <- data.frame(k = seq(1, 50, 1), overallaccuracy = rep(0, 50))  

# Use for loop to find k with highest accuracy
for (i in 1:50) {
  knn.pred<-knn(train_new[,-16],valid_dummy[,-16],
                cl=train_new[,16],k=i)
  accuracy[i,2]<-confusionMatrix(knn.pred,valid_dummy[,16])$overall[1]
} # loop for calculating the accuracy fo k=50
# Display accuracy for ten first k
kable(accuracy[1:10,], row.names = F, caption = "Accuracy")
```

```{r}
which(accuracy[,2] == max(accuracy[,2]))   # max accuracy
```

```{r}
# Plot accuracy for different k
ggplot(accuracy, aes(k, overallaccuracy)) + 
  geom_line() + 
  theme_minimal() +
  labs (title = "K nearest neighbours: Overall accuracy vs K", 
        y = "Accuracy", 
        x = "k nearest neigbours" )
```

```{r}
knn.pred.valid <- knn(train_new[, -16], valid_dummy[, -16], cl = train_new[, 16], k = 6 ,prob = T)     #prediction on validation data using best k=6
cmk <- confusionMatrix(knn.pred.valid,valid_dummy[,16])    #confusion matrix 
fourfoldplot(cmk$table, color = c("cyan", "pink"),
             conf.level = 0, margin = 1, main = "Confusion Matrix for KNN")     # plot confusion ma
cmk
```

## Classification tree

```{r}
cars_train[,6] <- as.factor(cars_train$is_claim)
train_downsampling <- downSample(cars_train[,-6],cars_train$is_claim,yname = "is_claim")
# Classification tree

tree_fit <- rpart(cars_train$is_claim ~.,
                  data = cars_train, # Data set
                  cp = 0.001,
                  method = "class") # Method: Classification


rpart.plot(tree_fit) # Plot the resulting tree


# Predict values for train set
pred_tree_tr <- predict(tree_fit,
                         cars_train[,c(-6)],
                         type ="class")

# Predict values for validation set
pred_tree_v_tr <- predict(tree_fit,
                         cars_validation[,c(-6)],
                         type ="class")



# Confusion matrix for classification tree with train set
conf_matrix_tree_tr <- confusionMatrix(
  pred_tree_tr,
  factor(cars_train$is_claim),
  positive = "1")

# plot confusion matrix
fourfoldplot(conf_matrix_tree_tr$table,
             color = c("cyan", "pink"),
             conf.level = 0,
             margin = 1,
             main = "Confusion Matrix for Classification Tree
             for train set") 

# Confusion matrix for classification tree with validation set
conf_matrix_tree_v <- confusionMatrix(
  pred_tree_v_tr,
  factor(cars_validation$is_claim),
  positive = "1")

# plot confusion matrix
fourfoldplot(conf_matrix_tree_v$table,
             color = c("cyan", "pink"),
             conf.level = 0,
             margin = 1,
             main = "Confusion Matrix for Classification
             Tree for validation set") 
```
Plotting the classification tree with trained data results in only 1 leaf. Such an output is surprising and shows that the model could not find any rules to explain the classification of positive outcomes. Let's continue by using an optimal cp and by pruning the tree.

```{r}
cp_optimal <- printcp(tree_fit)[
  which.min(printcp(tree_fit)[,'xerror']),
  'CP'] # Returns optimal CP value when checking xerror


pruned.tree <- prune(tree_fit, cp= cp_optimal) # Prune the train model with best cp


# Cross-validation

table_cp <- printcp(tree_fit) # Save cps

rows_small_errors_std <- head(order(table_cp[,5]),6) # Know the rows (folds) having  the smallest standard errors of the estimates

table_error <- matrix(table_cp[,4] + table_cp[,5]) # Sum the std error and the error

table_error <- cbind(table_cp[,1], # Include CP
                     table_cp[,2], # Include nsplit
                     table_error,  # Error + std error
                     table_cp[,5]) # Std error

rows_small_errors_std <- head(sort(table_error[,4]),6) # Know the rows (folds) having  the smallest std error

rows_small_errors_std # Display and chose the best size

# To be continued with best size...

```
We try to look at the lowest cp value to prune the tree. The found value equals 0 and translates again an issue.
It is known that we should not choose a tree based on it's cp, but we should choose a tree size. Ordinarilly, we would like to have a small tree with a small cp. Such a tree would avoid overfitting. Unfortunately, the resulting size for our case is 0.

We conclude that a tree of size 0 might express some issues in the data used. The issues could be in the observations themselves or in the variables used.

```{r}
# Pruning on Validation data
pred_tree_v_pruned <- predict(pruned.tree, # Pruned tree
                         cars_validation[,c(-6)],# Validation set
                         type ="class")

# Confusion matrix for classification tree with validation set
conf_matrix_tree_v <- confusionMatrix(
  pred_tree_v_pruned,
  factor(cars_validation$is_claim),
  positive = "1")

# plot confusion matrix
fourfoldplot(conf_matrix_tree_v$table,
             color = c("cyan", "pink"),
             conf.level = 0,
             margin = 1,
             main = "Confusion Matrix for Classification
             Tree (pruned) for validation set") 
```
The confusion matrix has classified correctly every observation for cases where the explanatory variable is negative. However, we see that it has classified even the positive claims. The model could be bad and chose to classify every observation as 0 since we noticed no rules in the fitted tree. Therefor, we should be careful and reluctant to state that the model is good at classifying negative claims.


## Logistic Regression

The logistic regression is a model that is also suited for binary response variables.

### Classical logistic regression

Building the model with a logit link function as it is usually the best suited one for the logistic regression
```{r}
cars.lg <- glm(is_claim ~., data= cars_final, family=binomial(link="logit"))

summary(cars.lg) # Displaying the resulting model
```

From the dummies born from "model" variable, only the one corresponding to model=5 is statistically significant. H0 cannot be rejected for the betas estimate of population_density and age_of_policyholder. <br>
<br>


```{r}
PlotResidLogist(cars.lg) # Deviance residuals
```

If we plot the deviance residuals, we notice that the positive residuals and negative ones each form a clear group. It is also the case for the pearson residuals. We can see a few extremes residuals (observations 3458,27165 and 37230).

```{r}
anova(cars.lg, test="Chisq")
```

According to the analysis of the deviance table, only population_density coul be unworth to be part of the model with p-value>0.05.


```{r}
HosLem.test(cars_final$is_claim, fitted(cars.lg))
```

"Warning: â€˜-â€™ not meaningful for factors" .... To remove from analysis probably



......... [ In progress, to continue and modify ]
